<!doctype html><html><head><meta charset=utf-8><title>A Beginner's Guide to Machine Learning Algorithms</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><link rel=stylesheet href=https://preview.acethecloud.com/plugins/slick/slick.css><link rel=stylesheet href=https://preview.acethecloud.com/plugins/slick/slick-theme.css><link rel=stylesheet href=https://preview.acethecloud.com/plugins/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=https://preview.acethecloud.com/plugins/magnafic-popup/magnific-popup.css><link href=https://preview.acethecloud.com/scss/style.min.css rel=stylesheet><link rel="shortcut icon" href=https://preview.acethecloud.com/images/favicon.ico type=image/x-icon><link rel=icon href=https://preview.acethecloud.com/images/favicon.png type=image/x-icon><script async src="https://www.googletagmanager.com/gtag/js?id=G-FCQTR1NVY6"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-FCQTR1NVY6")</script></head><body><nav class="navbar navbar-expand-lg fixed-top"><div class=container><a href=https://preview.acethecloud.com/ class=navbar-brand><img src=https://preview.acethecloud.com/images/site-navigation/logo.png alt=site-logo></a>
<button type=button class="navbar-toggler collapsed" data-toggle=collapse data-target=#navbarCollapse>
<span class=navbar-toggler-icon></span>
<span class=navbar-toggler-icon></span>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-between" id=navbarCollapse><ul class="nav navbar-nav main-navigation my-0 mx-auto"><li class=nav-item><a href=https://preview.acethecloud.com/#home class="nav-link text-dark text-sm-center p-2">Home</a></li><li class=nav-item><a href=https://preview.acethecloud.com/#about class="nav-link text-dark text-sm-center p-2">About</a></li><li class=nav-item><a href=https://preview.acethecloud.com/#resume class="nav-link text-dark text-sm-center p-2">Cloud</a></li><li class=nav-item><a href=https://preview.acethecloud.com/#skills class="nav-link text-dark text-sm-center p-2">Cloud Share</a></li><li class=nav-item><a href=https://preview.acethecloud.com/#contact class="nav-link text-dark text-sm-center p-2">Subscribe</a></li></ul><div class=navbar-nav><a href=https://preview.acethecloud.com/blog class="btn btn-primary btn-zoom hire_button">Blog</a></div></div></div></nav><div id=content><header class=breadCrumb><div class=container><div class=row><div class="col-lg-10 col-md-12 offset-lg-1 offset-md-0 text-center"><h3 class=breadCrumb__title>A Beginner's Guide to Machine Learning Algorithms</h3><nav aria-label=breadcrumb class="d-flex justify-content-center"><ol class="breadcrumb align-items-center"><li class=breadcrumb-item><a href=https://preview.acethecloud.com/>Home</a></li><li class=breadcrumb-item><a href=https://preview.acethecloud.com/blog>All Post</a></li><li class="breadcrumb-item active" aria-current=page>A Beginner's Guide to Machine Learning Algorithms</li></ol></nav></div></div><ul class=post-meta><li><i class="fa fa-calendar"></i>
December 10, 2022</li><li><i class="fa fa-clock-o"></i>
18 mins read</li><li><i class="fa fa-tag"></i>
<a class=text-capitalize href=https://preview.acethecloud.com/tags/ml/>ml</a>
<a class=text-capitalize href=https://preview.acethecloud.com/tags/model/>model</a>
<a class=text-capitalize href=https://preview.acethecloud.com/tags/algorithms/>algorithms</a></li><li><i class="fa fa-folder-open"></i>
<a class=text-capitalize href=https://preview.acethecloud.com/categories/blog/>blog</a></li></ul></div></div></div></div></header><section class="section singleBlog"><div class=svg-img><img src=https://preview.acethecloud.com/images/hero/figure-svg.svg alt></div><div class=animate-shape><img src=https://preview.acethecloud.com/images/skill/skill-background-shape.svg alt><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 600 600"><defs><linearGradient id="d" x1=".929" y1=".111" x2=".263" y2=".935" gradientUnits="objectBoundingBox"><stop offset="0" stop-color="#f1f6f9"/><stop offset="1" stop-color="#f1f6f9" stop-opacity="0"/></linearGradient></defs><g data-name="blob-shape (3)"><path class="blob" fill="url(#d)" d="M455.4 151.1c43.1 36.7 73.4 92.8 60.8 136.3-12.7 43.5-68.1 74.4-111.3 119.4-43.1 45-74 104.1-109.8 109-35.9 5-76.7-44.2-111.8-89.2-35.2-45-64.7-85.8-70.8-132.6-6-46.8 11.6-99.6 46.7-136.3 35.2-36.6 88-57.2 142.4-58.8 54.5-1.7 110.6 15.6 153.8 52.2z"/></g></svg></div><div class=animate-pattern><img src=https://preview.acethecloud.com/images/service/background-pattern.svg alt=background-shape></div><div class=container><div class=row><div class=col-lg-12><div class=singleBlog__feature><img src=https://preview.acethecloud.com/ alt=feature-image></div></div></div><div class="row mt-5"><div class=col-lg-12><div class=singleBlog__content><p>Machine learning algorithms are a set of techniques that allow computers to learn from data and make predictions or decisions without explicit programming. These algorithms can be broadly classified into three categories: supervised learning, unsupervised learning, and reinforcement learning.</p><h3 id=categories-of-machine-learning-algorithms>Categories of Machine Learning Algorithms</h3><h4 id=1-supervised-learning-algorithms>1. Supervised learning algorithms:</h4><p>Supervised learning algorithms are used when we have a dataset with labeled input and output examples. The goal of these algorithms is to learn a function that can map the input data to the corresponding output labels. Some examples of supervised learning algorithms are:</p><ul><li><p>Linear regression: This algorithm is used to predict a continuous outcome variable based on one or more predictor variables. It assumes a linear relationship between the predictor and the outcome variables.</p></li><li><p><strong>Logistic regression</strong> : This algorithm is used to predict a binary outcome variable based on one or more predictor variables. It is a generalized linear model that uses the sigmoid function to model the probability of the outcome variable being 1.</p></li><li><p><strong>Decision trees</strong> : This algorithm is used to build a tree-like model that can be used for classification or regression tasks. The model makes predictions by following the branches of the tree based on the values of the input data.</p></li><li><p><strong>Support vector machines (SVMs)</strong> : This algorithm is used for classification tasks and tries to find the hyperplane in a high-dimensional space that maximally separates the two classes.</p></li></ul><h4 id=2-unsupervised-learning-algorithms>2. Unsupervised learning algorithms:</h4><p>Unsupervised learning algorithms are used when we have a dataset with only input examples and no corresponding output labels. The goal of these algorithms is to find patterns or structures in the data. Some examples of unsupervised learning algorithms are:</p><ul><li><p><strong>K-means clustering</strong> : This algorithm is used to partition the data into k clusters based on the similarity of the data points. It does this by iteratively updating the centroids of the clusters until convergence.</p></li><li><p><strong>Hierarchical clustering</strong> : This algorithm is used to build a tree-like model that represents the relationships between the data points. It does this by iteratively merging the most similar data points into a cluster.</p></li><li><p><strong>Principal component analysis (PCA)</strong> : This algorithm is used to reduce the dimensionality of the data by projecting it onto a lower-dimensional space. It does this by finding the directions in the data with the highest variance and projecting the data onto these directions.</p></li></ul><h4 id=3-reinforcement-learning-algorithms>3. Reinforcement learning algorithms:</h4><p>Reinforcement learning algorithms are used to train an agent to take actions in an environment to maximize a reward signal. These algorithms are often used in robotics, self-driving cars, and game playing. Some examples of reinforcement learning algorithms are:</p><ul><li><p><strong>Q-learning</strong> : This algorithm is used to learn the optimal action-selection policy in a Markov decision process. It does this by iteratively updating a Q-table that represents the expected reward for each action in each state.</p></li><li><p><strong>Deep Q-network (DQN)</strong> : This algorithm is an extension of Q-learning that uses a neural network to approximate the Q-function. It has been used to achieve human-level performance in various Atari games.</p></li></ul><p>In summary, the choice of a machine learning algorithm depends on the type of data you have, the type of task you want to perform, and the resources you have available. It is important to understand the characteristics and limitations of each algorithm to make an informed decision about which one to use.</p><hr><h2 id=hands-on-with-supervised-learning-category-of-algorithms>Hands On with Supervised learning category of Algorithms</h2><h4 id=1-linear-regression>1. Linear Regression.</h4><p>Linear regression is a machine learning algorithm that is used for predicting a continuous target variable based on one or more explanatory variables. It is based on the idea of finding a linear relationship between the explanatory variables and the target variable.</p><p>Here is an example of linear regression in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># import the necessary libraries</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LinearRegression
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create some sample data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>2</span>], [<span style=color:#ae81ff>3</span>], [<span style=color:#ae81ff>4</span>], [<span style=color:#ae81ff>5</span>]])
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create a linear regression model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># fit the model to the data</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># predict the target variable for a new data point</span>
</span></span><span style=display:flex><span>prediction <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>6</span>]])
</span></span><span style=display:flex><span>print(prediction) <span style=color:#75715e># Output: [6.]</span>
</span></span></code></pre></div><p>In this example, we have a sample dataset with 5 data points, each with a single explanatory variable (X) and a target variable (y). We create a linear regression model and fit it to the data using the fit method. Then, we use the predict method to make a prediction for a new data point with an explanatory variable of 6.</p><p>The linear regression model learns the linear relationship between the explanatory and target variables by minimizing the sum of the squared errors between the predicted and actual values. The model parameters, such as the intercept and coefficients, are learned during the training process.</p><p>In summary, linear regression is a machine learning algorithm that is used for predicting a continuous target variable based on one or more explanatory variables. It is based on the idea of finding a linear relationship between the variables and can be implemented in Python using the scikit-learn library.</p><h4 id=2-logistic-regression>2. Logistic Regression</h4><p>Logistic regression is a type of classification algorithm that is used to predict a binary outcome, such as &ldquo;yes&rdquo; or &ldquo;no,&rdquo; &ldquo;0&rdquo; or &ldquo;1,&rdquo; or &ldquo;true&rdquo; or &ldquo;false.&rdquo; It is based on the logistic function, which maps a continuous input to a value between 0 and 1.</p><p>Here is an example of how to implement logistic regression in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># import the necessary libraries</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># load the data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># labels</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># split the data into training and testing sets</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create the logistic regression model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LogisticRegression()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># train the model on the training data</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># make predictions on the testing data</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># evaluate the model performance</span>
</span></span><span style=display:flex><span>accuracy <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>score(X_test, y_test)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Accuracy:&#34;</span>, accuracy)
</span></span></code></pre></div><p>In this code, the first step is to import the necessary libraries. Then, the data is loaded and split into training and testing sets. Next, the logistic regression model is created and trained on the training data using the fit function. The model is then used to make predictions on the testing data using the predict function. Finally, the model performance is evaluated using the score function, which returns the accuracy of the predictions.</p><p>Logistic regression is a simple and effective algorithm that can be used for a wide range of binary classification tasks. It is fast to train and easy to interpret, but it can be sensitive to the choice of the regularization parameter and may not perform well when there are non-linear relationships in the data.</p><h4 id=3-decision-trees>3. Decision Trees.</h4><p>Decision trees are a type of machine learning algorithm that can be used for both classification and regression tasks. They are based on the idea of creating a tree-like model of decisions, with each internal node representing a decision based on the value of a feature, and each leaf node representing the prediction.</p><p>Here is a simple example of how to train a decision tree classifier in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeClassifier
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># labels</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Split the data into training and testing sets</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the classifier</span>
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> DecisionTreeClassifier()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train the classifier on the training data</span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Test the classifier on the testing data</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the accuracy</span>
</span></span><span style=display:flex><span>accuracy <span style=color:#f92672>=</span> accuracy_score(y_test, y_pred)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Accuracy:&#34;</span>, accuracy)
</span></span></code></pre></div><p>In the above example, we first load the data and split it into training and testing sets using the train_test_split function from scikit-learn. Then, we create a DecisionTreeClassifier object and train it on the training data using the fit function. Finally, we test the classifier on the testing data and calculate the accuracy using the accuracy_score function.</p><p>Decision trees have several hyperparameters that can be tuned to improve the performance of the model, such as the maximum depth of the tree, the minimum number of samples required to split a node, and the criterion used to split the nodes. These hyperparameters can be set when creating the DecisionTreeClassifier object, as shown below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>clf <span style=color:#f92672>=</span> DecisionTreeClassifier(max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, min_samples_split<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, criterion<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gini&#39;</span>)
</span></span></code></pre></div><p>In this example, we set the maximum depth of the tree to 5, the minimum number of samples required to split a node to 10, and the criterion used to split the nodes to gini.</p><p>Decision trees are simple and easy to implement, and they can handle both numerical and categorical data. However, they can be prone to overfitting, especially if the tree is allowed to grow too deep. To prevent overfitting, it is recommended to use techniques such as pruning or setting a maximum depth for the tree.</p><ol start=4><li>Support vector machines (SVMs):</li></ol><p>Support vector machines (SVMs) are a type of machine learning algorithm that can be used for both classification and regression tasks. They are based on the idea of finding a hyperplane in the feature space that maximally separates the different classes or values.</p><p>Here is a simple example of how to train a linear SVM classifier in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># labels</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Split the data into training and testing sets</span>
</span></span><span style=display:flex><span>X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the classifier</span>
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> SVC(kernel<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;linear&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train the classifier on the training data</span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Test the classifier on the testing data</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Calculate the accuracy</span>
</span></span><span style=display:flex><span>accuracy <span style=color:#f92672>=</span> accuracy_score(y_test, y_pred)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Accuracy:&#34;</span>, accuracy)
</span></span></code></pre></div><p>In the above example, we first load the data and split it into training and testing sets using the train_test_split function from scikit-learn. Then, we create an SVC object with a linear kernel and train it on the training data using the fit function. Finally, we test the classifier on the testing data and calculate the accuracy using the accuracy_score function.</p><p>SVMs have several hyperparameters that can be tuned to improve the performance of the model, such as the kernel type, the regularization parameter, and the kernel-specific parameters. These hyperparameters can be set when creating the SVC object, as shown below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>clf <span style=color:#f92672>=</span> SVC(kernel<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rbf&#39;</span>, C<span style=color:#f92672>=</span><span style=color:#ae81ff>1.0</span>, gamma<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>)
</span></span></code></pre></div><p>In this example, we set the kernel type to RBF (radial basis function), the regularization parameter to 1.0, and the kernel-specific parameter to 0.1.</p><p>SVMs are powerful and effective machine learning algorithms, and they have been widely used in many applications. However, they can be sensitive to the choice of the hyperparameters and may require careful tuning to achieve good performance. They can also be computationally expensive to train, especially for large datasets.</p><hr><h2 id=hands-on-with-unsupervised-learning-category-of-algorithms>Hands On with Unsupervised learning category of Algorithms</h2><h4 id=1-k-means-clustering>1. K-means clustering</h4><p>K-means clustering is an unsupervised machine learning algorithm that is used to group data points into &ldquo;k&rdquo; clusters based on their similarity. It is based on the idea of iteratively assigning data points to the closest cluster center and then updating the cluster centers to the mean of the data points in the cluster.</p><p>Here is a simple example of how to use the k-means clustering algorithm in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.cluster <span style=color:#f92672>import</span> KMeans
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the KMeans object</span>
</span></span><span style=display:flex><span>kmeans <span style=color:#f92672>=</span> KMeans(n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit the data to the model</span>
</span></span><span style=display:flex><span>kmeans<span style=color:#f92672>.</span>fit(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Predict the cluster labels</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> kmeans<span style=color:#f92672>.</span>predict(X)
</span></span></code></pre></div><p>In the above example, we first load the data and create a KMeans object with the desired number of clusters (in this case, 3). Then, we fit the data to the model using the fit function, and predict the cluster labels for the data using the predict function.</p><p>K-means clustering has several hyperparameters that can be tuned to improve the performance of the model, such as the number of clusters (k), the initialization method, and the maximum number of iterations. These hyperparameters can be set when creating the KMeans object, as shown below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>kmeans <span style=color:#f92672>=</span> KMeans(n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, init<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k-means++&#39;</span>, max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>300</span>)
</span></span></code></pre></div><p>In this example, we set the number of clusters to 5, the initialization method to &lsquo;k-means++&rsquo;, and the maximum number of iterations to 300.</p><p>K-means clustering is a fast and effective algorithm that is widely used for clustering tasks. However, it can be sensitive to the initial conditions and may not always produce the best clusters. It is also important to choose an appropriate value for the number of clusters (k), as the performance of the algorithm can depend on it.</p><h4 id=2-hierarchical-clustering>2. Hierarchical clustering</h4><p>Hierarchical clustering is a machine learning technique that is used to group data points into clusters based on their similarity. It is an unsupervised learning method that does not require labeled data.</p><p>In hierarchical clustering, the data points are initially considered as individual clusters, and then they are merged into larger clusters based on their similarity. There are two main types of hierarchical clustering: agglomerative and divisive. Agglomerative hierarchical clustering starts with the individual data points and merges them into larger clusters, while divisive hierarchical clustering starts with a single cluster and divides it into smaller clusters.</p><p>Here is a simple example of how to perform agglomerative hierarchical clustering in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.cluster <span style=color:#f92672>import</span> AgglomerativeClustering
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the clustering model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> AgglomerativeClustering(n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit the model to the data</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Predict the clusters for each data point</span>
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit_predict(X)
</span></span></code></pre></div><p>In the above example, we first load the data and create an AgglomerativeClustering object with the desired number of clusters. Then, we fit the model to the data using the fit function, and predict the clusters for each data point using the fit_predict function.</p><p>Hierarchical clustering has several hyperparameters that can be tuned to achieve the best performance for the given task, such as the number of clusters, the distance measure, and the linkage criterion. These hyperparameters can be set when creating the AgglomerativeClustering object, as shown below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model <span style=color:#f92672>=</span> AgglomerativeClustering(n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, affinity<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;euclidean&#39;</span>, linkage<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ward&#39;</span>)
</span></span></code></pre></div><p>In this example, we set the number of clusters to 5, the distance measure to euclidean, and the linkage criterion to ward.</p><p>Hierarchical clustering is a simple and effective technique that can be used for a wide range of tasks. However, it can be sensitive to the choice of the distance measure and the linkage criterion, and may not always produce meaningful clusters. It is also computationally expensive for large datasets.</p><h4 id=3-principal-component-analysis-pca>3. Principal component analysis (PCA)</h4><p>Principal component analysis (PCA) is a machine learning technique that is used for dimensionality reduction and data visualization. It is based on the idea of projecting the data onto a lower-dimensional space, such that the new features are orthogonal (uncorrelated) and capture the most variation in the data.</p><p>Here is a simple example of how to perform PCA in Python using the scikit-learn library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.decomposition <span style=color:#f92672>import</span> PCA
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the data</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> <span style=color:#f92672>...</span> <span style=color:#75715e># features</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the PCA model</span>
</span></span><span style=display:flex><span>pca <span style=color:#f92672>=</span> PCA(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit the model to the data</span>
</span></span><span style=display:flex><span>pca<span style=color:#f92672>.</span>fit(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Transform the data to the new space</span>
</span></span><span style=display:flex><span>X_transformed <span style=color:#f92672>=</span> pca<span style=color:#f92672>.</span>transform(X)
</span></span></code></pre></div><p>In the above example, we first load the data and create a PCA object with the desired number of components (in this case, 2). Then, we fit the model to the data using the fit function, and transform the data to the new space using the transform function. The transformed data can then be plotted or used for further analysis.</p><p>PCA has several hyperparameters that can be tuned to adjust the behavior of the algorithm, such as the number of components to keep and the method used to compute the principal components. These hyperparameters can be set when creating the PCA object, as shown below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>pca <span style=color:#f92672>=</span> PCA(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>0.95</span>, svd_solver<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;full&#39;</span>)
</span></span></code></pre></div><p>In this example, we set the number of components to 0.95, which means that the model will keep enough components to retain 95% of the variance in the data. We also set the svd_solver to &lsquo;full&rsquo;, which specifies the method used to compute the principal components.</p><p>PCA is a fast and effective method for dimensionality reduction and data visualization. However, it can be sensitive to the scaling of the data, and it does not preserve the structure of the original data. It is also important to keep in mind that the principal components are sensitive to the choice of the origin and the direction of the axes, and may not always correspond to meaningful features in the data.</p><hr><h2 id=hands-on-with-reinforcement-learning-category-of-algorithms>Hands On with Reinforcement learning category of Algorithms</h2><h4 id=1-q-learning>1. Q-learning</h4><p>Q-learning is a type of reinforcement learning algorithm that is used to learn the optimal action to take in a given state. It is based on the idea of creating a &ldquo;Q-table&rdquo; that stores the expected reward for taking a particular action in a given state. The Q-table is updated iteratively as the agent interacts with the environment and receives rewards.</p><p>Here is a simple example of how to implement a Q-learning algorithm in Python:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the discount factor</span>
</span></span><span style=display:flex><span>discount_factor <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.9</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the initial Q-table</span>
</span></span><span style=display:flex><span>Q <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((num_states, num_actions))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the learning rate</span>
</span></span><span style=display:flex><span>learning_rate <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set the number of iterations</span>
</span></span><span style=display:flex><span>num_iterations <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_iterations):
</span></span><span style=display:flex><span>    <span style=color:#75715e># Select a random state</span>
</span></span><span style=display:flex><span>    state <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>0</span>, num_states)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Select an action based on the current state</span>
</span></span><span style=display:flex><span>    action <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>argmax(Q[state, :] <span style=color:#f92672>+</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>1</span>, num_actions) <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1.</span> <span style=color:#f92672>/</span> (i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Take the action and observe the reward and next state</span>
</span></span><span style=display:flex><span>    reward, next_state <span style=color:#f92672>=</span> take_action(state, action)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Update the Q-table</span>
</span></span><span style=display:flex><span>    Q[state, action] <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> learning_rate) <span style=color:#f92672>*</span> Q[state, action] <span style=color:#f92672>+</span> learning_rate <span style=color:#f92672>*</span> (reward <span style=color:#f92672>+</span> discount_factor <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>max(Q[next_state, :]))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># Use the Q-table to make predictions</span>
</span></span><span style=display:flex><span>predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>argmax(Q, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span></code></pre></div><p>In the above example, we first initialize the Q-table with zeros and set the discount factor, learning rate, and number of iterations. Then, we loop over the number of iterations and select a random state, select an action based on the current state and the Q-table, take the action and observe the reward and next state, and update the Q-table using the observed reward and the maximum expected reward for the next state. Finally, we use the Q-table to make predictions by selecting the action with the maximum expected reward for each state.</p><p>Q-learning is a powerful reinforcement learning algorithm that can be used to solve a wide range of problems. However, it can be computationally expensive and may require fine-tuning of the hyperparameters, such as the learning rate and the discount factor, to achieve good performance.</p><h4 id=2-deep-q-network>2. Deep Q-network</h4><p>Deep Q-network (DQN) is a type of reinforcement learning algorithm that is used to learn a policy for choosing actions in an environment in order to maximize a reward. It is based on the idea of using a neural network to approximate the action-value function (Q-function), which represents the expected long-term reward for taking a specific action in a specific state.</p><p>Here is a simple example of how to implement a DQN in Python using the keras library:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> keras
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras.models <span style=color:#f92672>import</span> Sequential
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Dense
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the environment</span>
</span></span><span style=display:flex><span>env <span style=color:#f92672>=</span> <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the Q-network</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> Sequential()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(Dense(<span style=color:#ae81ff>64</span>, input_dim<span style=color:#f92672>=</span>env<span style=color:#f92672>.</span>observation_space<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(Dense(env<span style=color:#f92672>.</span>action_space<span style=color:#f92672>.</span>n, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;linear&#39;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the learning rate and the loss function</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mse&#39;</span>, optimizer<span style=color:#f92672>=</span>keras<span style=color:#f92672>.</span>optimizers<span style=color:#f92672>.</span>Adam(lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the replay buffer</span>
</span></span><span style=display:flex><span>replay_buffer <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the epsilon-greedy policy</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>epsilon_greedy_policy</span>(state, epsilon<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>):
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>rand() <span style=color:#f92672>&lt;</span> epsilon:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> env<span style=color:#f92672>.</span>action_space<span style=color:#f92672>.</span>sample()
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    q_values <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(state)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>argmax(q_values)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the training loop</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> episode <span style=color:#f92672>in</span> range(num_episodes):
</span></span><span style=display:flex><span>  <span style=color:#75715e># Reset the environment</span>
</span></span><span style=display:flex><span>  state <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>reset()
</span></span><span style=display:flex><span>  state <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>expand_dims(state, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> t <span style=color:#f92672>in</span> range(max_timesteps):
</span></span><span style=display:flex><span>    <span style=color:#75715e># Select an action according to the epsilon-greedy policy</span>
</span></span><span style=display:flex><span>    action <span style=color:#f92672>=</span> epsilon_greedy_policy(state)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Take the action and observe the next state and reward</span>
</span></span><span style=display:flex><span>    next_state, reward, done, _ <span style=color:#f92672>=</span> env<span style=color:#f92672>.</span>step(action)
</span></span><span style=display:flex><span>    next_state <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>expand_dims(next_state, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Store the experience in the replay buffer</span>
</span></span><span style=display:flex><span>    replay_buffer<span style=color:#f92672>.</span>append((state, action, reward, next_state, done))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># Update the state</span>
</span></span><span style=display:flex><span>    state <span style=color:#f92672>=</span> next_state
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># If the episode is done, break the inner loop</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> done:
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>      
</span></span><span style=display:flex><span>  <span style=color:#75715e># Sample a batch of experiences from the replay buffer</span>
</span></span><span style=display:flex><span>  batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span>  experiences <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>sample(replay_buffer, batch_size)
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e># Extract the states, actions, rewards, next states, and done flags from the batch</span>
</span></span><span style=display:flex><span>  states, actions, rewards, next_states, dones <span style=color:#f92672>=</span> zip(<span style=color:#f92672>*</span>experiences)
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e># Convert the states and next states to a numpy array</span>
</span></span><span style=display:flex><span>  states <span style=color:#f92672>=</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Predict the Q-values of the next states</span>
</span></span><span style=display:flex><span>  next_q_values <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(next_states)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Set the Q-values of the terminal states to 0</span>
</span></span><span style=display:flex><span>  next_q_values[dones] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Calculate the targets</span>
</span></span><span style=display:flex><span>  targets <span style=color:#f92672>=</span> rewards <span style=color:#f92672>+</span> gamma <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>max(next_q_values, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Predict the Q-values of the current states</span>
</span></span><span style=display:flex><span>  q_values <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(states)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Update the Q-values of the actions taken</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> i, action <span style=color:#f92672>in</span> enumerate(actions):
</span></span><span style=display:flex><span>    q_values[i][action] <span style=color:#f92672>=</span> targets[i]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># Train the model on the states and updated Q-values</span>
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>fit(states, q_values, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span></code></pre></div><p>In the above code, we first predict the Q-values of the next states using the model. Then, we set the Q-values of the terminal states to 0. This is because there is no future reward for the terminal states. Next, we calculate the targets for each state-action pair using the rewards and the Q-values of the next states.</p><p>Then, we predict the Q-values of the current states using the model. Finally, we update the Q-values of the actions taken in the batch using the targets, and train the model on the states and updated Q-values using the fit function.</p><p>This is a simplified version of a DQN implementation, and there are several additional techniques that can be used to improve the performance, such as using a target network to stabilize the training, using a replay buffer to break the temporal correlations in the data, and using a prioritized replay buffer to focus on the most important experiences.</p><p>In summary, DQN is a type of reinforcement learning algorithm that is used to learn a policy for choosing actions in an environment in order to maximize a reward. It is based on the idea of using a neural network to approximate the action-value function and using the Bellman equation to update the Q-values of the actions taken. There are several techniques that can be used to improve the performance of a DQN, such as using a target network, a replay buffer, and a prioritized replay buffer.</p></div></div></div></div></section></div><section class=footer id=contact><div class=footer__background_shape><svg viewBox="0 0 1920 79"><path d="M0 0h1920v79L0 0z" data-name="Path 1450"/></svg></div><div class=container><div class=row><div class=col-lg-12><div class=footer__cta><div class=shape-1><svg xmlns="http://www.w3.org/2000/svg" width="357" height="315.029" viewBox="0 0 357 315.029"><path data-name="Path 1449" d="M76.1-157.222C91.746-135.8 87.2-94.273 99.993-61.945c12.7 32.328 42.661 55.459 39.248 73.282-3.318 17.823-40.007 30.337-65.6 43.325-25.5 12.988-39.912 26.545-60.01 42.566-20.1 16.116-46.074 34.6-63.328 27.682-17.349-6.921-25.976-39.153-59.915-59.82s-93.1-29.768-105.325-51.478 22.373-56.028 43.609-93.949c21.331-37.921 29.2-79.35 53.563-96.793 24.459-17.444 65.414-10.9 103.9-6.921 38.396 3.982 74.326 5.404 89.965 26.829z" transform="translate(217.489 188.626)"/></svg></div><div class=shape-2><svg xmlns="http://www.w3.org/2000/svg" width="357" height="315.029" viewBox="0 0 357 315.029"><path data-name="Path 1449" d="M76.1-157.222C91.746-135.8 87.2-94.273 99.993-61.945c12.7 32.328 42.661 55.459 39.248 73.282-3.318 17.823-40.007 30.337-65.6 43.325-25.5 12.988-39.912 26.545-60.01 42.566-20.1 16.116-46.074 34.6-63.328 27.682-17.349-6.921-25.976-39.153-59.915-59.82s-93.1-29.768-105.325-51.478 22.373-56.028 43.609-93.949c21.331-37.921 29.2-79.35 53.563-96.793 24.459-17.444 65.414-10.9 103.9-6.921 38.396 3.982 74.326 5.404 89.965 26.829z" transform="translate(217.489 188.626)"/></svg></div><div class="text-light footer__cta_content"><span>Contact me</span><h3 class=mb-0>Let’s Discuss on your Cloud Journey</h3></div><div class=footer__cta_action><a class="btn btn-light btn-zoom" href=https://preview.acethecloud.com/contact>Get in
touch</a></div></div></div></div><div class="row footer__widget"><div class=col-lg-4><div class="footer__widget_logo mb-5"><img src=https://preview.acethecloud.com/images/contact/widget-logo.png style=width:400px alt=widget-logo></div></div><div class=col-lg-4 style=margin-left:100px><div class="text-light footer__widget_address mb-5"><h4 class=base-font>Sitemap</h4><ul class="unstyle-list small"><li class=mb-2><a class=text-light href=https://preview.acethecloud.com/about>About Author</a></li><li class=mb-2><a class=text-light href=https://preview.acethecloud.com/>Frequently Ask Question</a></li><li class=mb-2><a class=text-light href=https://preview.acethecloud.com/>Privacy & Policy</a></li><li class=mb-2><a class=text-light href=https://preview.acethecloud.com/>Latest Article</a></li></ul><h4 class=base-font>Address</h4><ul class="fa-ul small"><li class=mb-2><a class=text-light href=tel:><span class=fa-li><i class="fa fa-phone"></i></span></a></li><li class=mb-2><a class=text-light href=mailto:><span class=fa-li><i class="fa fa-envelope"></i></span></a></li><li class=mb-2><span class=fa-li><i class="fa fa-map-marker"></i></span></a></li></ul></div></div></div><div class="row footer__footer"><div class=col-lg-6><div class="footer__footer_copy text-light"><p>Copyright 2023 - All Rights Reserved by <a class=text-light href=https://AceTheOps.com/ target=_blank>AceTheOps</a></p></div></div><div class=col-lg-6><div class=footer__footer_social><ul class=unstyle-list><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://www.facebook.com/><i class="fa fa-facebook-official"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://www.linkedin.com/><i class="fa fa-linkedin-square"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://www.pinterest.com/><i class="fa fa-pinterest-square"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://twitter.com/AceTheCloud><i class="fa fa-twitter-square"></i></a></li></ul></div></div></div></div></section><script src="https://maps.googleapis.com/maps/api/js?key=&libraries=geometry"></script>
<script src=https://preview.acethecloud.com/plugins/jQuery/jquery.min.js></script>
<script src=https://preview.acethecloud.com/plugins/bootstrap/bootstrap.min.js></script>
<script src=https://preview.acethecloud.com/plugins/slick/slick.min.js></script>
<script src=https://preview.acethecloud.com/plugins/waypoint/jquery.waypoints.min.js></script>
<script src=https://preview.acethecloud.com/plugins/magnafic-popup/jquery.magnific-popup.min.js></script>
<script src=https://preview.acethecloud.com/plugins/tweenmax/TweenMax.min.js></script>
<script src=https://preview.acethecloud.com/plugins/imagesloaded/imagesloaded.min.js></script>
<script src=https://preview.acethecloud.com/plugins/masonry/masonry.min.js></script>
<script src=https://preview.acethecloud.com/js/script.min.js></script></body></html>